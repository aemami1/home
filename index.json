[{"authors":null,"categories":null,"content":"I\u0026rsquo;m an Assistant Professor at the Department of Computer Science at Brock University. My broad interests are in Artificial Intelligence and Natural Language Processing with a recent primary focus on addressing the generalizability, interpretability, and ethical implications of large language models (LLMs). Through this, I\u0026rsquo;m aiming to contribute to the responsible and efficient development of AI technologies in the future.\nI received my PhD in Computer Science in 2021 from McGill University and Mila, supervised by Dr. Jackie Cheung. My PhD research was at the intersection of Natural Language Inference (NLI) and common-sense reasoning in AI Systems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1719934157,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I\u0026rsquo;m an Assistant Professor at the Department of Computer Science at Brock University. My broad interests are in Artificial Intelligence and Natural Language Processing with a recent primary focus on addressing the generalizability, interpretability, and ethical implications of large language models (LLMs).","tags":null,"title":"Ali Emami","type":"authors"},{"authors":["Abhishek Kumar","Robert Morabito","Sanzhar Umbet","Jad Kabbara","Ali Emami"],"categories":null,"content":"This paper has been accepted for publication at the ACL 2024 Main Conference, to be held in August 2024. The ACL Anthology link will be available after the conference.\n","date":1718409600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"9c08cba6203c4becc34bf055dece7e5c","permalink":"https://aemami.ca/publication/kumar-2024-confidence/","publishdate":"2024-06-15T00:00:00Z","relpermalink":"/publication/kumar-2024-confidence/","section":"publication","summary":"As the use of Large Language Models (LLMs) becomes more widespread, understanding their self-evaluation of confidence in generated responses becomes increasingly important as it is integral to the reliability of the output of these models. We introduce the concept of Confidence-Probability Alignment, that connects an LLM's internal confidence, quantified by token probabilities, to the confidence conveyed in the model's response when explicitly asked about its certainty. Using various datasets and prompting techniques that encourage model introspection, we probe the alignment between models' internal and expressed confidence. These techniques encompass using structured evaluation scales to rate confidence, including answer options when prompting, and eliciting the model's confidence level for outputs it does not recognize as its own. Notably, among the models analyzed, OpenAI's GPT-4 showed the strongest confidence-probability alignment, with an average Spearman's ρ^ of 0.42, across a wide range of tasks. Our work contributes to the ongoing efforts to facilitate risk assessment in the application of LLMs and to further our understanding of model trustworthiness.","tags":null,"title":"Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models","type":"publication"},{"authors":["Brendan Park","Madeline Janecek","Naser Ezzati-Jivan","Yifeng Li","Ali Emami"],"categories":null,"content":"This paper has been accepted for publication at the ACL 2024 Main Conference, to be held in August 2024. The ACL Anthology link will be available after the conference.\n","date":1716595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"f57a7dedbc235b051a7def3e827d6a4f","permalink":"https://aemami.ca/publication/park-2024-winovis/","publishdate":"2024-05-25T00:00:00Z","relpermalink":"/publication/park-2024-winovis/","section":"publication","summary":"Large Language Models (LLMs) have demonstrated remarkable success in tasks like the Winograd Schema Challenge (WSC), showcasing advanced textual common-sense reasoning. However, applying this reasoning to multimodal domains, where understanding text and images together is essential, remains a substantial challenge. To address this, we introduce WinoVis, a novel dataset specifically designed to probe text-to-image models on pronoun disambiguation within multimodal contexts. Utilizing GPT-4 for prompt generation and Diffusion Attentive Attribution Maps (DAAM) for heatmap analysis, we propose a novel evaluation framework that isolates the models' ability in pronoun disambiguation from other visual processing challenges. Evaluation of successive model versions reveals that, despite incremental advancements, Stable Diffusion 2.0 achieves a precision of 56.7% on WinoVis, only marginally surpassing random guessing. Further error analysis identifies important areas for future research aimed at advancing text-to-image models in their ability to interpret and interact with the complex visual world.","tags":null,"title":"Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge","type":"publication"},{"authors":["Abhishek Kumar","Sarfaroz Yunusov","Ali Emami"],"categories":null,"content":"This paper has been accepted for presentation at the ACL 2024 Main Conference, to be held in August 2024. The ACL Anthology link will be available after the conference.\n","date":1716422400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"ac4e00b7b30aca528180971bbbabc4a5","permalink":"https://aemami.ca/publication/kumar-2024-subtle/","publishdate":"2024-05-23T00:00:00Z","relpermalink":"/publication/kumar-2024-subtle/","section":"publication","summary":"Research on Large Language Models (LLMs) has often neglected subtle biases that, although less apparent, can significantly influence the models' outputs toward particular social narratives. This study addresses two such biases within LLMs: representative bias, which denotes a tendency of LLMs to generate outputs that mirror the experiences of certain identity groups, and affinity bias, reflecting the models' evaluative preferences for specific narratives or viewpoints. We introduce two novel metrics to measure these biases: the Representative Bias Score (RBS) and the Affinity Bias Score (ABS), and present the Creativity-Oriented Generation Suite (CoGS), a collection of open-ended tasks such as short story writing and poetry composition, designed with customized rubrics to detect these subtle biases. Our analysis uncovers marked representative biases in prominent LLMs, with a preference for identities associated with being white, straight, and men. Furthermore, our investigation of affinity bias reveals distinctive evaluative patterns within each model, akin to 'bias fingerprints'. This trend is also seen in human evaluators, highlighting a complex interplay between human and machine bias perceptions.","tags":null,"title":"Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models","type":"publication"},{"authors":["Jing Han Sun","Ali Emami"],"categories":null,"content":"","date":1714521600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"58ab1c2edf0aabdbda7f75b39238fef3","permalink":"https://aemami.ca/publication/sun-2024-evo/","publishdate":"2024-05-01T00:00:00Z","relpermalink":"/publication/sun-2024-evo/","section":"publication","summary":"While Large Language Models (LLMs) excel at the Winograd Schema Challenge (WSC), a coreference resolution task testing common-sense reasoning through pronoun disambiguation, they struggle with instances that feature minor alterations or rewording. To address this, we introduce EvoGrad, an open-source platform that harnesses a human-in-the-loop approach to create a dynamic dataset tailored to such altered WSC instances. Leveraging ChatGPT's capabilities, we expand our task instances from 182 to 3691, setting a new benchmark for diverse common-sense reasoning datasets. Additionally, we introduce the error depth metric, assessing model stability in dynamic tasks. Our results emphasize the challenge posed by EvoGrad: Even the best performing LLM, GPT-3.5, achieves an accuracy of 65.0% with an average error depth of 7.2, a stark contrast to human performance of 92.8% accuracy without perturbation errors. This highlights ongoing model limitations and the value of dynamic datasets in uncovering them.","tags":null,"title":"EvoGrad: A Dynamic Take on the Winograd Schema Challenge with Human Adversaries","type":"publication"},{"authors":["Pardis Sadat Zahraei","Ali Emami"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"128cd3cc0b679ec7b52c7b555db82fe3","permalink":"https://aemami.ca/publication/zahraei-2024-wsc/","publishdate":"2024-06-28T23:12:02.247873Z","relpermalink":"/publication/zahraei-2024-wsc/","section":"publication","summary":"The Winograd Schema Challenge (WSC) serves as a prominent benchmark for evaluating machine understanding. While Large Language Models (LLMs) excel at answering WSC questions, their ability to generate such questions remains less explored. In this work, we propose Tree-of-Experts (ToE), a novel prompting method which enhances the generation of WSC instances (50% valid cases vs. 10% in recent methods). Using this approach, we introduce WSC+, a novel dataset comprising 3,026 LLM-generated sentences. Notably, we extend the WSC framework by incorporating new ‘ambiguous’ and ‘offensive’ categories, providing a deeper insight into model overconfidence and bias. Our analysis reveals nuances in generation-evaluation consistency, suggesting that LLMs may not always outperform in evaluating their own generated questions when compared to those crafted by other models. On WSC+, GPT-4, the top-performing LLM, achieves an accuracy of 68.7%, significantly below the human benchmark of 95.1%.","tags":null,"title":"WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts","type":"publication"},{"authors":["Ali Emami"],"categories":null,"content":"","date":1690243200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"a67745db623068a776590a03b8540dab","permalink":"https://aemami.ca/publication/emami-2023-challenge/","publishdate":"2023-07-25T00:00:00Z","relpermalink":"/publication/emami-2023-challenge/","section":"publication","summary":"The primary objective of Artificial Intelligence (AI) is to empower computers to perform tasks necessitating intellectual capabilities. These tasks include complex decision-making and planning, vision or perception, and comprehending human language. Natural Language Processing (NLP) is an AI subfield dedicated to devising and implementing models, systems, and algorithms to tackle problems related to understanding human language, such as translation, question answering, and summarization. This chapter serves as an introductory guide to the essential tasks, methods, and challenges in NLP. It offers a concise overview of popular NLP tasks, accompanied by background information and terminology. The chapter discusses common evaluation methods and metrics, as well as a summary of state-of-the-art results across various key tasks. It then delves into a detailed examination of current NLP methods, with a focus on deep learning approaches. The chapter also presents a discussion on common-sense reasoning in NLP, including recent challenges and developed techniques.","tags":["Natural Language Processing","Artificial Intelligence","Deep Learning","Common-sense Reasoning"],"title":"Natural Language Processing: Current Methods and Challenges","type":"publication"},{"authors":["Robert Morabito","Jad Kabbara","Ali Emami"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"7aa34787ef06a8f444bc20beb1069585","permalink":"https://aemami.ca/publication/morabito-2023-debiasing/","publishdate":"2024-06-28T23:12:02.224878Z","relpermalink":"/publication/morabito-2023-debiasing/","section":"publication","summary":"Debiasing methods that seek to mitigate the tendency of Language Models (LMs) to occasionally output toxic or inappropriate text have recently gained traction. In this paper, we propose a standardized protocol which distinguishes methods that yield not only desirable results, but are also consistent with their mechanisms and specifications. For example, we ask, given a debiasing method that is developed to reduce toxicity in LMs, if the definition of toxicity used by the debiasing method is reversed, would the debiasing results also be reversed? We used such considerations to devise three criteria for our new protocol: Specification Polarity, Specification Importance, and Domain Transferability. As a case study, we apply our protocol to a popular debiasing method, Self-Debiasing, and compare it to one we propose, called Instructive Debiasing, and demonstrate that consistency is as important an aspect to debiasing viability as is simply a desirable result. We show that our protocol provides essential insights into the generalizability and interpretability of debiasing methods that may otherwise go overlooked.","tags":null,"title":"Debiasing should be good and bad: Measuring the consistency of debiasing techniques in language models","type":"publication"},{"authors":["Qi Chen Gao","Ali Emami"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"6f81ec555b574acb39147bce6a5735c7","permalink":"https://aemami.ca/publication/gao-2023-turing/","publishdate":"2024-06-28T23:12:02.236276Z","relpermalink":"/publication/gao-2023-turing/","section":"publication","summary":"In this paper, we study the viability of the deployment of language models towards non-playable character (NPC) scripts, by introducing a novel pipeline for the automatic construction of NPC scripts using Transformer-based believable scripts for a variety of game genres and specifications. In addition, we propose a self-diagnosis method inspired by previous work to develop language models, tailored specifically to desirable NPC qualities such as coherency, believability, and degree of repetition. Finally, we propose a new benchmark, called The Turing Quest, which we use to show that the pipeline, when applied to GPT-3, can generate for a variety of game genres and contexts, NPC scripts that can fool judges in thinking they have been written by humans. We believe that these findings can greatly benefit both the gaming industry and its global community of users, since many current games continue to base their NPCs on manually-curated scripts that are resource-demanding and may curb the immersiveness and enjoyment of the user.","tags":null,"title":"The Turing Quest: Can Transformers Make Good NPCs?","type":"publication"},{"authors":["Darren Abramson","Ali Emami"],"categories":null,"content":"","date":164376e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"1003fb83b92eb9fe7d7a895a14d3b4d9","permalink":"https://aemami.ca/publication/abramson-2021-interp/","publishdate":"2022-02-02T00:00:00Z","relpermalink":"/publication/abramson-2021-interp/","section":"publication","summary":"Codex is a machine learning model of natural and programming languages to which OpenAI provides limited third-party access. 1 Github Copilot is a commercial product that is built on Codex. 2 In this paper, we describe some scientific concerns with Codex/Copilot that dovetail with its widely discussed ethical and legal problems. Our focus is on the scientific problems that attend Codex, with consequent weaknesses for the Copilot commercial service. In our view, ethical and scientific weaknesses are closely tied, and we describe this with a few instances. The argument of the paper is as follows: GPT-3, the natural language model on which Codex is built, and that services such as Copilot ultimately depend on, suffers from scientific deficiencies. First we present critical remarks on Copilot’s structure and underlying language model. We then present paths forward for these, identifying specific architectural features that prevent GPT-3 from competing with recent advances due to freely distributed and licensed research software.","tags":null,"title":"Interpreting docstrings without using common sense: the private science of very large language models","type":"publication"},{"authors":["Darren Abramson","Ali Emami"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"9d7405a1dc22a5d42b3be53f3d05bf77","permalink":"https://aemami.ca/publication/abramson-2022-application/","publishdate":"2024-06-28T23:12:02.219177Z","relpermalink":"/publication/abramson-2022-application/","section":"publication","summary":"Language models built using semi-supervised machine learning on large corpora of natural language have very quickly enveloped the fields of natural language generation and understanding. In this paper we apply a zero-shot approach independently developed by a number of researchers now gaining recognition as a significant alternative to fine-tuning for evaluation on common sense tasks. A language model with relatively few parameters and training steps compared to a more recent language model (T5) can outperform it on a recent large data set (TimeDial), while displaying robustness in its performance across a similar class of language tasks. Surprisingly, this result is achieved by using a hyperparameter-free zero-shot method with the smaller model, compared to fine-tuning to the larger model. We argue that robustness of the smaller model ought to be understood in terms of compositionality, in a sense that we draw from recent literature on a class of similar models. We identify a practical cost for our method and model: high GPU-time for natural language evaluation. The zero-shot measurement technique that produces remarkable stability, both for ALBERT and other BERT variants, is an application of pseudo-log-likelihoods to masked language models for the relative measurement of probability for substitution alternatives in forced choice language tasks such as the Winograd Schema Challenge, Winogrande, and others. One contribution of this paper is to bring together a number of similar, but independent strands of research. We produce some absolute state-of-the-art results for common sense reasoning in binary choice tasks, performing better than any published result in the literature, including fine-tuned efforts. We show a remarkable consistency of the model's performance under adversarial settings, which we argue is best explained by the model's compositionality of representations.","tags":null,"title":"An application of pseudo-log-likelihoods to natural language scoring","type":"publication"},{"authors":["Ali Emami","Ian Porada","Alexandra Olteanu","Kaheer Suleman","Adam Trischler","Jackie Chi Kit Cheung"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"919c6d9fb2abcca467be4de0388e9e85","permalink":"https://aemami.ca/publication/emami-2021-adept/","publishdate":"2024-06-28T23:12:02.213047Z","relpermalink":"/publication/emami-2021-adept/","section":"publication","summary":"A false contract is more likely to be rejected than a contract is, yet a false key is less likely than a key to open doors. While correctly interpreting and assessing the effects of such adjective-noun pairs (e.g., false key) on the plausibility of given events (e.g., opening doors) underpins many natural language understanding tasks, doing so often requires a significant degree of world knowledge and common-sense reasoning. We introduce ADEPT – a large-scale semantic plausibility task consisting of over 16 thousand sentences that are paired with slightly modified versions obtained by adding an adjective to a noun. Overall, we find that while the task appears easier for human judges (85% accuracy), it proves more difficult for transformer-based models like RoBERTa (71% accuracy). Our experiments also show that neither the adjective itself nor its taxonomic class suffice in determining the correct plausibility judgement, emphasizing the importance of endowing automatic natural language understanding systems with more context sensitivity and common-sense reasoning.","tags":null,"title":"ADEPT: An Adjective-Dependent Plausibility Task","type":"publication"},{"authors":["Omar Alam","Anshuman Kush","Ali Emami","Parisa Pouladzadeh"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"388fd56220cf80f8b6eb8887ed9dda18","permalink":"https://aemami.ca/publication/alam-2021-predicting/","publishdate":"2024-06-28T23:12:02.201388Z","relpermalink":"/publication/alam-2021-predicting/","section":"publication","summary":"Intelligent transportation systems (ITS) play an important role in the quality of life of citizens in any metropolitan city. Despite various policies and strategies incorporated to increase the reliability and quality of service, public transportation authorities continue to face criticism from commuters largely due to irregularities in bus arrival times, most notably manifested in early or late arrivals. Due to these irregularities, commuters may miss important appointments, wait for too long at the bus stop, or arrive late for work. Therefore, accurate prediction models are needed to build better customer service solutions for transit systems, e.g. building accurate mobile apps for trip planning or sending bus delay/cancel notifications. Prediction models will also help in developing better appointment scheduling systems for doctors, dentists, and other businesses to take into account transit bus delays for their clients. In this paper, we seek to predict the occurrence of arrival time irregularities by mining GPS coordinates of transit buses provided by the Toronto Transit Commission (TTC) along with hourly weather data and using this data in machine learning models that we have developed. In our study, we compared the performance of a Long Short Term Memory Recurrent Neural Network (LSTM) model against four baseline models, an Artificial Neural Network (ANN), Support Vector Regression (SVR), Autoregressive Integrated Moving Average (ARIMA) and historical averages. We found that our LSTM model demonstrates the best prediction accuracy. The improved accuracy achieved by the LSTM model may lend itself to its ability to adjust and update the weights of neurons while accounting for long-term dependencies. In addition, we found that weather conditions play a significant role in improving the accuracy of our models. Therefore, we built a prediction model that combines an LSTM model with a Recurrent Neural Network Model (RNN) that focuses on the weather condition. Our findings also reveal that in nearly 37% of scheduled arrival times, buses either arrive early or late by a margin of more than 5 min, suggesting room for improvement in the current strategies employed by transit authorities.","tags":null,"title":"Predicting irregularities in arrival times for transit buses with recurrent neural networks using GPS coordinates and weather data","type":"publication"},{"authors":[],"categories":[],"content":" This post describes how one can set up a personal website using the Hugo Academic theme for the static site generator Hugo and publish it automatically with GitHub Pages. It is targeted towards readers who have a basic understanding of how to use git from the command line and who already have a GitHub account. This post is based on Hugo Extended 0.73.0 and Hugo Academic 0.49, which were the respective latest releases at the time of writing (July 2020).\nThe final goal will be to have two GitHub repositories: a source repository that contains the website\u0026rsquo;s unprocessed resources and a host repository that hosts the the generated website. We will use GitHub Actions to automatically deploy from the source to the host repository, i.e., if a change to the website is commited and pushed to the source repository, our GitHub Actions setup will auto-generate the actual website with Hugo and create a new commit on the host repository.\n1. Prerequisites As stated above, you need to have a GitHub account and at least some familiarity with using git from the command line. Furthermore, you also need to install Hugo on your machine, such that you can build and test your website locally before deploying it. The easiest way to set up Hugo is to download and unpack the latest release from the Hugo releases website on GitHub. For more information on installing Hugo, refer to the official installation instructions.\n2. Create source repository As a first step, we will create a new source repository on GitHub. It will hold your website\u0026rsquo;s unprocessed sources, from which the website\u0026rsquo;s HTML documents will be built. The official docs recommend to fork the Academic Kickstart repository. However, this prevents you from making your source repository private, which is why I decided to take a different route and manually duplicate the Academic Kickstart repository to my GitHub account:\nCreate a new repository on GitHub, e.g., academic-kickstart. You can safely make it private, but do not initialize it with at README. In this post, I will call the source repository academic-kickstart-demo and it is available here.\nClone the Academic Kickstart repository from https://github.com/sourcethemes/academic-kickstart, replace the URL of origin with your source repository\u0026rsquo;s URL, and push it to GitHub:\ngit clone git@github.com:sourcethemes/academic-kickstart.git academic-kickstart-demo cd academic-kickstart-demo git remote set-url origin git@github.com:sloede/academic-kickstart-demo.git git push Make sure to replace the URL of the source repository with your own!\n3. Set up initial website Before proceeding to make modifications, you should have a look at the initial state of the website and verify that everything works. To do this, you first need to initialize the git submodules by running\ngit submodule update --init --recursive This step is required once after you clone your source repository to a new location, as it will download necessary files for the Hugo Academic theme to work. Then, you can build your website locally by executing hugo, which will generate the website and place all files in the public/ directory. Alternatively, you can also start a local webserver with\nhugo server which will build the website and make it available at http://localhost:1313. In this mode Hugo will automatically re-generate your site whenever you change your sources, which comes in handy while developing your contents. Initial state of the website before any modifications. Now it is time to set up the initial website. A full description of what to do can be found in the official Getting Started guide. The most important files to configure your website are the following:\nconfig/_default/config.toml: Overall website configuration. config/_default/params.toml: Parameters for individual features. config/_default/menus.toml: Configure main navigation bar. content/authors/admin/_index.md: Details about the main user (you!). Due to extensive inline documentation, all files are more or less self-explaining. The content/ subfolder contains all user-editable source files from which the website is built. For the initial setup, disable all sections on the main homepage for which you do not have created your own content yet by either deleting them from content/home or by moving them to a different folder.\nHere is a short todo list to help you set up initially. To see the respective changes in the academic-kickstart-demo repository, click on the linked git commit:\nEdit config/_default/config.toml and change title to your website\u0026rsquo;s title (diff). Edit config/_default/params.toml and make the following modifications (diff): Disable edit_page by commenting it out (prepend with #). Edit the contact details like email, phone etc. Everything you do not need, you can just comment out by prepending a # symbol. Disable showing a map by setting engine to 0 in the [map] section. Disable unused widgets on the homepage by executing git mv content/home content/home-unused mkdir content/home git mv content/home-unused/index.md content/home/ git mv content/home-unused/about.md content/home/ git mv content/home-unused/contact.md content/home/ and edit config/_default/menus.toml and comment out the entries for Posts, Projects, and Publications (diff). Update the main user (diff): Rename the folder content/author/admin to your name, replacing spaces by dashes and keeping everything lowercase: git mv content/authors/admin content/authors/carl-friedrich-gauss Edit content/authors/carl-friedrich-gauss/_index.md and enter your information. Most importantly, change the username under authors: from admin to your new username (= folder name under content/authors/), e.g., carl-friedrich-gauss. Edit content/home/about.md and change author from admin to your new username. Use hugo/hugo server to verify that everything is set up correctly (even if most useful content is still missing) and git push the source repository to GitHub.\n4. Create and set up host repository GitHub Pages allows you to host static websites on GitHub, which is ideal for websites generated with a static site generator such as Hugo. For each project (= repository) you have on GitHub, the corresponding GitHub pages website will be available under\nhttps://YOUR-GITHUB-USERNAME.github.com/YOUR-PROJECT-NAME For the special project name YOUR-GITHUB-USERNAME.github.com, the website will be served directly under\nhttps://YOUR-GITHUB-USERNAME.github.com That is, without the project name suffix. For example, for my GitHub user account sloede, the special project name is sloede.github.com and the website is available under https://sloede.github.com (this will actually redirect you to this website).\nIn this tutorial, we will use academic-pages-demo as the host repository name, since my canonical repository name sloede.github.com is obviously already taken. Go to GitHub and create a new repository, in my case academic-pages-demo. As per the documentation, your host repository needs to be public unless you are on a GitHub Pro account. This time, also tick the box to initialize the repository with a README for testing purposes. On your newly created host repository site, go to Settings, scroll down to the GitHub Pages section and select master branch as your website source. Please note that in my case the URL differs from what you will see since I have already set up a custom domain for my GitHub Pages. GitHub Pages settings to select which branch to serve as a website. Now your host repository\u0026rsquo;s content (currently only the README file) will be available online and you can make sure that everything works by clicking on the link in the green box: Initial GitHub Pages website showing the README file. Before we proceed to auto-deploy your website, we will quickly verify that the GitHub Pages displays the Hugo Academic website properly. To do this, perform the following steps:\nDelete the existing public/ folder in your local clone of the source repository and clone your host repository as the public/ subfolder: rm -rf public/ git clone git@github.com:sloede/academic-pages-demo.git public Rebuild website: hugo Remove the README.md file (as otherwise your website will not be shown), add all files in public/ to git, and commit \u0026amp; push: cd public git rm README.md git add . git ci -m \u0026#39;Initial commit of Hugo Academic website\u0026#39; git push cd .. When you go to the GitHub Pages URL of your host repository, the website should now look something like this: GitHub Pages website showing Hugo Academic website. Congratulations, your initial website is now online! To avoid accidental manual commits to the host repository, especially after we have set up automatic deployment in the next section, delete the .git folder from the public/ subdirectory:\nrm -rf public/.git 5. Automatically publish changes in source repository on your website As the last step, we will enable the automatic deployment from your source repository to your host repository. That is, whenever you push changes to your website to the source repository, we want to automatically update the host repository - and thus the actual website - as well. Since we created two separate repositories for the website\u0026rsquo;s sources and its processed files, we first need to create a deploy key to allow the source repository to automatically update the host repository. Following the instructions for creating a deploy key at https://github.com/peaceiris/actions-gh-pages, you need to perform the following steps:\nGenerate an SSH key pair by executing ssh-keygen -t rsa -b 4096 -C \u0026#34;$(git config user.email)\u0026#34; -f gh-pages -N \u0026#34;\u0026#34; This will create two files: the public key gh-pages.pub and the private key gh-pages. Go to the repository settings of the source repository (here: academic-kickstart-demo), go to Secrets, and add a new secret with the name ACTIONS_DEPLOY_KEY (spelled exactly like this) and the contents of your secret key file gh-pages as the value: Add SSH secret key as new secret ACTIONS_DEPLOY_KEY to source repository. Go to the repository settings of the host repository (here: academic-pages-demo), go to Deploy Keys, and add a new deploy key with the title ACTIONS_DEPLOY_KEY (academic-kickstart-demo) and the contents of your public key file gh-pages.pub as the value. Make sure that the box for Allow write access is checked, as otherwise the source repository will not be able to update the host repository: Add SSH public key as new deploy key to host repository. Unlike for the newly added secret in the source repository, the exact title of the deploy key is not relevant for the automated deployment to work, but I recommend a descriptive name that reveals its purpose. After you have added the secret and the deploy key to the source and host repositories, you should delete the SSH key files, as their contents will not be needed again (and in case of the secret key, it is a security issue to leave it around): rm gh-pages gh-pages.pub With the deploy key in place, we can proceed to automatically update the host repository whenever a commit is pushed to the source repository. For this purpose, we will use GitHub Actions and create a workflow file that checks out the source repository, builds the website using Hugo, and adds the generated files to a new commit to the host repository.\nGo to your local clone of the source repository and create the GitHub Actions workflows directory:\nmkdir -p .github/workflows Next, create a new workflow file in .github/workflows, e.g., .github/workflows/GitHubPages.yml, with the following content:\nname: GitHub Pages on: push: branches: - master jobs: deploy: runs-on: ubuntu-20.04 steps: - uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes (true OR recursive) # fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.73.0\u0026#39; extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} publish_dir: ./public publish_branch: master # deploying branch cname: academic-pages-demo.lakemper.eu allow_empty_commit: true external_repository: sloede/academic-pages-demo Here, I will briefly explain each part of the file so you know what it does:\nSet name of this workflow to identify it on GitHub. name: GitHub Pages Execute this workflow whenever someone pushes to master: on: push: branches: - master Run a deploy job with a number of steps to execute (will be described below). Execute the job on a virtual machine running Ubuntu 20.04. jobs: deploy: runs-on: ubuntu-20.04 steps: [...] A list of available virtual machines can be found in the GitHub documentation. I recommend to use a machine as close as possible to your personal system to avoid surprises. Check out the source repository using one of the GitHub-provided \u0026ldquo;actions\u0026rdquo;, which is just a fancy term for a script specifically written to be run in GitHub workflows. - uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes (true OR recursive) # fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod Download and install Hugo using the peaceiris/actions-hugo action. The extended version of Hugo is required for the Hugo Academic theme to work, and I recommend to use the same Hugo version number as you use locally. - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.73.0\u0026#39; extended: true Build the website and minify, i.e., try to reduce the website file size. By default, Hugo will place the resulting files in the public/ subdirectory. - name: Build run: hugo --minify Deploy the built website to your host repository using the peaceiris/actions-gh-pages action. The value of deploy_key must match the secret key name you used before, here it is called ACTIONS_DEPLOY_KEY. The publish_dir must match the directory to which hugo writes its generated files (default: public/). The publish_branch is the same branch that you selected above when you set up the host repository. cname should be set to the custom domain name you serve your GitHub Pages from, and can be omitted if no custom domain is configured. With allow_empty_commit, any push to the source repository will trigger a new commit to the host repository, even if there were no user-visible changes. The external_repository must be the name of your host repository on GitHub, i.e., its web URL without the https://github.com/ part. - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} publish_dir: ./public publish_branch: master # deploying branch cname: academic-pages-demo.lakemper.eu allow_empty_commit: true external_repository: sloede/academic-pages-demo Once the workflow file is in place, add, commit \u0026amp; push it to the source repository:\ngit add .github/workflows/GitHubPages.yml git ci -m \u0026#39;Add workflow to automatically deploy website\u0026#39; git push The corresponding commit to the academic-kickstart-demo repository can be found here. You can verify that the workflow succeeded by going to your source repository website on GitHub - next to the latest commit info should be a small green checkmark: This workflow succeeded without errors. If you see a small brown circle instead of the checkmark, your action is still running. If the workflow indicator is a red cross, however, it means that something went wrong.\nSimilarly, you can check the host repository for a new commit, which will reference the commit to the source repository from which the current website was built: Automatically created commit on the host repository. 6. Where to go from here If everything went smoothly, you now have your own website online, generated from the Hugo Academic theme and auto-deployed to GitHub Pages. Your immediate next steps should be to update your user information (such that the dummy text provided by the academic-kickstart repository can be thrown out). Then, you can successively build up your personal website by either following the Hugo Academic documentation or by just experimenting. Always remember to only ever commit to the source repository directly, since manual commits to the host repository will be overwritten by the next automatic deployment.\nOnce your basic site is up and running, you can consider more advanced steps such as configuring a custom domain, adding support for comments as described here, or customizing the theme.\n","date":1594536673,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719653759,"objectID":"94f77c3ef183421a39f57970df6535ba","permalink":"https://aemami.ca/blog/getting-started-with-hugo-academic-and-github-pages/","publishdate":"2020-07-12T06:51:13Z","relpermalink":"/blog/getting-started-with-hugo-academic-and-github-pages/","section":"blog","summary":"How to set up a personal website with Hugo Academic and auto-deploy to GitHub Pages","tags":[],"title":"Getting Started With Hugo Academic and Github Pages","type":"blog"},{"authors":["Ali Emami","Adam Trischler","Kaheer Suleman","Jackie Chi Kit Cheung"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"c9ca6a854c65533b532bc311f3384a4d","permalink":"https://aemami.ca/publication/emami-2020-analysis/","publishdate":"2024-06-28T23:12:02.207272Z","relpermalink":"/publication/emami-2020-analysis/","section":"publication","summary":"The Winograd Schema Challenge (WSC) and variants inspired by it have become important benchmarks for common-sense reasoning (CSR). Model performance on the WSC has quickly progressed from chance-level to near-human using neural language models trained on massive corpora. In this paper, we analyze the effects of varying degrees of overlaps that occur between these corpora and the test instances in WSC-style tasks. We find that a large number of test instances overlap considerably with the pretraining corpora on which state-of-the-art models are trained, and that a significant drop in classification accuracy occurs when models are evaluated on instances with minimal overlap. Based on these results, we provide the WSC-Web dataset, consisting of over 60k pronoun disambiguation problems scraped from web data, being both the largest corpus to date, and having a significantly lower proportion of overlaps with current pretraining corpora.","tags":null,"title":"An analysis of dataset overlap on winograd-style tasks","type":"publication"},{"authors":["Ali Emami","Adam Trischler","Kaheer Suleman","Jackie Chi Kit Cheung"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"7aa81bb86b208a69702a90619c914faf","permalink":"https://aemami.ca/publication/emami-2018-generalized/","publishdate":"2024-06-28T23:12:02.177954Z","relpermalink":"/publication/emami-2018-generalized/","section":"publication","summary":"We introduce an automatic system that performs well on two common-sense reasoning tasks, the Winograd Schema Challenge (WSC) and the Choice of Plausible Alternatives (COPA). Problem instances from these tasks require diverse, complex forms of inference and knowledge to solve. Our method uses a knowledge-hunting module to gather text from the web, which serves as evidence for candidate problem resolutions. Given an input problem, our system generates relevant queries to send to a search engine. It extracts and classifies knowledge from the returned results and weighs it to make a resolution. Our approach improves F1 performance on the WSC by 0.16 over the previous best and is competitive with the state-of-the-art on COPA, demonstrating its general applicability.","tags":null,"title":"A generalized knowledge hunting framework for the winograd schema challenge","type":"publication"},{"authors":["Ali Emami","Noelia De La Cruz","Adam Trischler","Kaheer Suleman","Jackie Chi Kit Cheung"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"8c1160bf543e98fed85ca4c9a9f0344c","permalink":"https://aemami.ca/publication/emami-2018-knowledge/","publishdate":"2024-06-28T23:12:02.183826Z","relpermalink":"/publication/emami-2018-knowledge/","section":"publication","summary":"We introduce an automatic system that achieves state-of-the-art results on the Winograd Schema Challenge (WSC), a common sense reasoning task that requires diverse, complex forms of inference and knowledge. Our method uses a knowledge hunting module to gather text from the web, which serves as evidence for candidate problem resolutions. Given an input problem, our system generates relevant queries to send to a search engine, then extracts and classifies knowledge from the returned results and weighs them to make a resolution. Our approach improves F1 performance on the full WSC by 0.21 over the previous best and represents the first system to exceed 0.5 F1. We further demonstrate that the approach is competitive on the Choice of Plausible Alternatives (COPA) task, which suggests that it is generally applicable.","tags":null,"title":"A knowledge hunting framework for common sense reasoning","type":"publication"},{"authors":["Paul Trichelair","Ali Emami","Adam Trischler","Kaheer Suleman","Jackie Chi Kit Cheung"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"45d31dc4dcad8eca7f64eceb0d8a8e92","permalink":"https://aemami.ca/publication/trichelair-2018-reasonable/","publishdate":"2024-06-28T23:12:02.195514Z","relpermalink":"/publication/trichelair-2018-reasonable/","section":"publication","summary":"Recent studies have significantly improved the state-of-the-art on common-sense reasoning (CSR) benchmarks like the Winograd Schema Challenge (WSC) and SWAG. The question we ask in this paper is whether improved performance on these benchmarks represents genuine progress towards common-sense-enabled systems. We make case studies of both benchmarks and design protocols that clarify and qualify the results of previous work by analyzing threats to the validity of previous experimental designs. Our protocols account for several properties prevalent in common-sense benchmarks including size limitations, structural regularities, and variable instance difficulty.","tags":null,"title":"How reasonable are common-sense reasoning tasks: A case-study on the Winograd schema challenge and SWAG","type":"publication"},{"authors":["Ali Emami","Paul Trichelair","Adam Trischler","Kaheer Suleman","Hannes Schulz","Jackie Chi Kit Cheung"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"2f7f78c92333966e94cb49a78dc460b9","permalink":"https://aemami.ca/publication/emami-2018-knowref/","publishdate":"2024-06-28T23:12:02.189647Z","relpermalink":"/publication/emami-2018-knowref/","section":"publication","summary":"We introduce a new benchmark for coreference resolution and NLI, KnowRef, that targets common-sense understanding and world knowledge. Previous coreference resolution tasks can largely be solved by exploiting the number and gender of the antecedents, or have been handcrafted and do not reflect the diversity of naturally occurring text. We present a corpus of over 8,000 annotated text passages with ambiguous pronominal anaphora. These instances are both challenging and realistic. We show that various coreference systems, whether rule-based, feature-rich, or neural, perform significantly worse on the task than humans, who display high inter-annotator agreement. To explain this performance gap, we show empirically that state-of-the art models often fail to capture context, instead relying on the gender or number of candidate antecedents to make a decision. We then use problem-specific insights to propose a data-augmentation trick called antecedent switching to alleviate this tendency in models. Finally, we show that antecedent switching yields promising results on other tasks as well: we use it to achieve state-of-the-art results on the GAP coreference task.","tags":null,"title":"The KnowRef coreference corpus: Removing gender and number cues for difficult pronominal anaphora resolution","type":"publication"},{"authors":null,"categories":null,"content":" 2024:\nHonored to receive the 2024 Faculty of Mathematics and Science Excellence in Teaching Award (June).\n3 out of 3 submitted papers accepted at the main conference at The 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024, August 11-16). Massive congratulations to all collaborators, of which many were undergraduates and first year MSc\u0026rsquo;s! Stay tuned for the paper links (May).\nOur paper \u0026ldquo;EvoGrad: An open-source platform for Winograd Schema Challenge instances\u0026rdquo; accepted at The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024, May 20-25). [ArXiv] (May)\nOur paper \u0026ldquo;WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts\u0026rdquo; accepted as an Oral Presentation at The 18th Conference of the European Chapter of the Association for Computational Linguistics (EACL2024, March 17-22). [ACL-Anthology] [ArXiv] (March)\nExcited to give a talk at the Brock Faculty of Math and Science\u0026rsquo;s Anthropocene Research Colloquium Series on Friday, March 8: \u0026ldquo;Large Language Models: Society\u0026rsquo;s Silent Mirrors\u0026rdquo; (March).\n2023:\nOur paper \u0026ldquo;Debiasing should be Good and Bad: Measuring the Consistency of Debiasing Techniques in Language Models\u0026rdquo; published at The Findings of ACL 2023. [ACL-Anthology] [ArXiv] [Oral Presentation] [News Article] (January)\nPublished book chapter \u0026ldquo;Natural Language Processing: Current Methods and Challenges\u0026rdquo; in Engineering Mathematics and Artificial Intelligence: Foundations, Methods, and Applications. [SpringerLink] [Amazon]\nAwarded the 2023 New Frontiers in Research Fund (NFRF) Exploration Grant ($200,000 two-year support). [Brock News Article] (April)\nInvited to speak about my research at the SKEMA AI School for Business, during their AI integration seminar (August).\nInvited to discuss \u0026ldquo;Navigating the Power and Pitfalls of Pretrained Language Models in the Prompting Era\u0026rdquo; at the MIT Media Lab (May).\n2022:\nAwarded the 2022 NSERC Discovery Grant ($125,000, five-year support) and 2022 Discovery Launch Supplement ($12,500). [Brock News Article] (June)\nPublished \u0026ldquo;Interpreting docstrings without using common sense: the private science of very large language models\u0026rdquo; for Free Software Foundation (FSF): Philosophical and Legal Questions around Copilot, 2022. [FSF]\nKeynote speaker at the International Symposium on \u0026ldquo;Role of Basic Sciences for Sustainable Development\u0026rdquo; (October).\nDelivered insights on AI integration in a seminar at SKEMA AI School for Business (July).\nMasterclass presentation at SKEMA AI School for Business on \u0026ldquo;Generalizable, Ethical, and Interpretable Natural Language Processing: Science or Science Fiction?\u0026rdquo; (June).\n2021: Gave a talk titled \u0026ldquo;Towards Interpretable, Ethical, and Generalizable NLP Models\u0026rdquo; for a graduate seminar at the Department of Computer Science, Lakehead University, Thunder Bay, Canada (October).\n2020: Selected for an oral presentation at the 28th International Conference on Computational Linguistics (COLING 2020) (December).\n2019:\nGave an oral presentation of our research at the 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019) (July).\nProgram Committee member at 2019 ACL Student Research Workshop (SRW).\nKeynote at the Annual Microsoft Research and Mila Collaborative Research Workshop (October).\n2018: Presented our awarded outstanding paper at the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop (NAACL 2018) (June).\n","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719683358,"objectID":"f16fbd58616139583332c38b045fa1a7","permalink":"https://aemami.ca/news/news/","publishdate":"2017-12-01T00:00:00Z","relpermalink":"/news/news/","section":"news","summary":"List of news.\n","tags":[],"title":"News","type":"news"},{"authors":["Ali Emami","Malgorzata E Willinska","Hood Thabit","Lalantha Leelarathna","Sara Hartnell","Sibylle Dellweg","Carsten Benesch","Julia K Mader","Manuel Holzer","Harald Kojzar"," others"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"1dd609ffbded3efbcf1fc55127b7c910","permalink":"https://aemami.ca/publication/emami-2017-behavioral/","publishdate":"2024-06-28T23:12:02.171689Z","relpermalink":"/publication/emami-2017-behavioral/","section":"publication","summary":" **Objectives:** We evaluated patterns of meal intake, insulin bolus delivery, and fingerstick glucose measurements during hybrid closed-loop and sensor-augmented pump (SAP) therapy, including associations with glucose control. **Methods:** Data were retrospectively analyzed from pump-treated adults with type 1 diabetes who underwent, in random order, 12 weeks free-living closed-loop (n = 32) and 12 weeks SAP (n = 33) periods. We quantified daily patterns of main meals, snacks, prandial insulin boluses, correction boluses, and fingerstick glucose measurements by analyzing data recorded on the study glucometer and on study insulin pump. **Results:** We analyzed 1942 closed-loop days and 2530 SAP days. The total number of insulin boluses was reduced during closed-loop versus SAP periods by mean 1.0 per day (95% confidence interval 0.6-1.4, P \u003c 0.001) mainly because of a reduced number of correction boluses by mean 0.7 per day (0.4-1.0, P \u003c 0.001). Other behavioral patterns were unchanged. The carbohydrate content of snacks but not the number of snacks was positively correlated with (1) glycemic variability as measured by standard deviation of sensor glucose (closed-loop P \u003c 0.05; SAP P \u003c 0.01), (2) mean sensor glucose (P \u003c 0.05), and (3) postintervention HbA1c (P \u003c 0.05). Behavioral patterns explained 47% of between-subject variance in glucose variability during SAP period and 30%-33% of variance of means sensor glucose and postintervention HbA1c. **Conclusion:** Fewer correction boluses are delivered during closed-loop period. The size of snacks appears to worsen glucose control possibly because of carbohydrate-rich content of snacks. Modifiable behavioral patterns may be important determinants of glucose control.","tags":null,"title":"Behavioral patterns and associations with glucose control during 12-week randomized free-living clinical trial of day and night hybrid closed-loop insulin delivery in adults with type 1 diabetes","type":"publication"},{"authors":["Nadine Taleb","Ali Emami","Corinne Suppere","Virginie Messier","Laurent Legault","Jean-Louis Chiasson","Rémi Rabasa-Lhoret","Ahmad Haidar"],"categories":null,"content":" ","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"6c650d82f4238142834ee63d24360764","permalink":"https://aemami.ca/publication/taleb-2016-comparison/","publishdate":"2024-06-28T23:12:02.153587Z","relpermalink":"/publication/taleb-2016-comparison/","section":"publication","summary":"**Background**: Despite technological advances, the accuracy of continuous glucose monitoring (CGM) systems may not always be satisfactory with rapidly changing glucose levels, as is notable during exercise. We compare the performance of two current and widely used CGM systems, Dexcom G4 Platinum (Dexcom) and Medtronic Paradigm Veo Enlite system (Enlite), during both rest and exercise in adults with type 1 diabetes (T1D). **Research design and methods**: Paired sensor and plasma glucose (PG) values (total of 431 data pairs for Dexcom and 425 for Enlite) were collected from 17 adults (37.3 ± 13.6 years) with T1D. To evaluate and compare the accuracy of sensor readings, criteria involving sensor bias (sensor minus PG levels), absolute relative difference (ARD), and percentage of readings meeting International Organization for Standardization (ISO) criteria were considered. **Results**: Both Dexcom and Enlite performed equally well during the rest period, with respective mean/median biases of -0.12/-0.02 mmol/L versus -0.18/-0.40 (P = 0.78, P = 0.66) mmol/L and ARDs of 13.77/13.34% versus 12.38/11.95% (P = 0.53, P = 0.70). During exercise, sensor bias means/medians were -0.40/-0.21 mmol versus -0.26/-0.24 mmol/L (P = 0.67, P = 0.62) and ARDs were 22.53/15.13% versus 20.44/14.11% (P = 0.58, P = 0.68) for Dexcom and Enlite, respectively. Both sensors demonstrated significantly lower performance during exercise; median ARD comparison at rest versus exercise for both Dexcom and Enlite showed a P = 0.02. More data pairs met the ISO criteria for Dexcom and Enlite at rest, 73.6% and 76.9% compared with exercise 48.2% and 53.9%. **Conclusion**: Dexcom and Enlite demonstrated comparable overall performances during rest and physical activity. However, a lower accuracy was observed during exercise for both sensors, necessitating a fine-tuning of their performance with physical activity.","tags":null,"title":"Comparison of two continuous glucose monitoring systems, Dexcom G4 Platinum and Medtronic Paradigm Veo Enlite System, at rest and during exercise","type":"publication"},{"authors":["Nadine Taleb","Ali Emami","Corinne Suppere","Virginie Messier","Laurent Legault","Martin Ladouceur","Jean-Louis Chiasson","Ahmad Haidar","Rémi Rabasa-Lhoret"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"9de764769fd1fc9bbe7b29edee7a6048","permalink":"https://aemami.ca/publication/taleb-2016-efficacy/","publishdate":"2024-06-28T23:12:02.16556Z","relpermalink":"/publication/taleb-2016-efficacy/","section":"publication","summary":"**Aims/hypothesis**: The aim of this study was to assess whether the dual-hormone (insulin and glucagon) artificial pancreas reduces hypoglycaemia compared with the single-hormone (insulin alone) artificial pancreas during two types of exercise. **Methods**: An open-label randomised crossover study comparing both systems in 17 adults with type 1 diabetes (age, 37.2 ± 13.6 years; HbA1c, 8.0 ± 1.0% [63.9 ± 10.2 mmol/mol]) during two exercise types on an ergocycle and matched for energy expenditure: continuous (60% [Formula: see text] for 60 min) and interval (2 min alternating periods at 85% and 50% [Formula: see text] for 40 min, with two 10 min periods at 45% [Formula: see text] at the start and end of the session). Blocked randomisation (size of four) with a 1:1:1:1 allocation ratio was computer generated. The artificial pancreas was applied from 15:30 hours until 19:30 hours; exercise was started at 18:00 hours and announced 20 min earlier to the systems. The study was conducted at the Institut de recherches cliniques de Montréal. **Results**: During single-hormone control compared with dual-hormone control, exercise-induced hypoglycaemia (plasma glucose \u003c3.3 mmol/l with symptoms or \u003c3.0 mmol/l regardless of symptoms) was observed in four (23.5%) vs two (11.8%) interventions (p = 0.5) for continuous exercise and in six (40%) vs one (6.25%) intervention (p = 0.07) for interval exercise. For the pooled analysis (single vs dual hormone), the median (interquartile range) percentage time spent at glucose levels below 4.0 mmol/l was 11% (0.0-46.7%) vs 0% (0-0%; p = 0.0001) and at glucose levels between 4.0 and 10.0 mmol/l was 71.4% (53.2-100%) vs 100% (100-100%; p = 0.003). Higher doses of glucagon were needed during continuous (0.126 ± 0.057 mg) than during interval exercise (0.093 ± 0.068 mg) (p = 0.03), with no reported side-effects in all interventions. **Conclusions/interpretation**: The dual-hormone artificial pancreas outperformed the single-hormone artificial pancreas in regulating glucose levels during announced exercise in adults with type 1 diabetes.","tags":null,"title":"Efficacy of single-hormone and dual-hormone artificial pancreas during continuous and interval exercise in adult patients with type 1 diabetes: randomised controlled crossover trial","type":"publication"},{"authors":["Ali Emami","Joseph El Youssef","Remi Rabasa-Lhoret","Joelle Pineau","Jessica R Castle","Ahmad Haidar"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"f3ad9a1026485007a9c0b569c27c61d1","permalink":"https://aemami.ca/publication/emami-2016-modeling/","publishdate":"2024-06-28T23:12:02.159598Z","relpermalink":"/publication/emami-2016-modeling/","section":"publication","summary":"The dual-hormone artificial pancreas is an emerging technology to treat type 1 diabetes (T1D). It consists of a glucose sensor, infusion pumps, and a dosing algorithm that directs hormonal delivery. Preclinical optimization of dosing algorithms using computer simulations has the potential to accelerate the pace of development for this technology. However, current simulation environments consider glucose regulation models that either do not include glucagon action submodels or include submodels that were proposed without comparison to other candidate models. We consider here nine candidate models of glucagon action featuring a number of possible characteristics: insulin-independent glucagon action, insulin/glucagon ratio effect on hepatic glucose production, insulin-dependent suppression of glucagon action, and the effect of rate of change of glucagon. To assess the models, we use measurements of plasma insulin, plasma glucagon, and endogenous glucose production collected from experiments involving eight subjects with T1D who receive four subcutaneous glucagon boluses. We estimate each model's parameters using a Bayesian approach, and the models are contrasted based on the deviance information criterion. The model achieving the best fit features insulin-dependent suppression of glucagon action and incorporates effects of both glucagon levels and its rate of change.","tags":null,"title":"Modeling glucagon action in patients with type 1 diabetes","type":"publication"},{"authors":["Ali Emami","Remi Rabasa-Lhoret","Ahmad Haidar"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"86752a47c4872976023aa70f5822cf7c","permalink":"https://aemami.ca/publication/emami-2015-enhancing/","publishdate":"2024-06-28T23:12:02.141437Z","relpermalink":"/publication/emami-2015-enhancing/","section":"publication","summary":"**Background:** Computer simulation environments have been used in the development of many artificial pancreas systems. A glucose sensor model is an essential part of these environments, and different models have been proposed. However, not one of these models accounts for drop-outs of sensor readings, a well-known phenomenon caused by physical pressure on the sensor site. In this work, we have proposed an enhanced model that accounts for drop-outs and demonstrated its improvement over the existing one-compartment model.\n**Materials and methods:** Potential drop-outs were augmented to the existing model, and their incidences and magnitudes were estimated simultaneously with the model parameters using the Bayesian approach. Drop-outs and model parameters were estimated from data collected from 15 subjects with type 1 diabetes who underwent an artificial pancreas study. Model fitting and parameter estimates were contrasted between the enhanced model and the existing one-compartment model.\n**Results:** Both models achieved similar parameter estimates (P=not significant) and were all physiologically plausible. The enhanced model further estimated 1.71 drop-outs per day, which improved model fit (weighted residual reduced from [minimum -4%, maximum 3%] to [-3%, 2%]) and reduced significantly the deviance information criteria from 2739.72 to 1456.00.\n**Conclusions:** The enhanced model improves fitting of glucose levels and should allow more realistic simulations that assesses artificial pancreas systems.","tags":null,"title":"Enhancing glucose sensor models: modeling the drop-outs","type":"publication"},{"authors":["Nadine Taleb","Ahmad Haidar","Corinne Suppere","Ali Emami","Virginie Messier","Laurent Legault","Jean-Louise Chiasson","Remi Rabasa-Lhoret"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"3839c43a464bc75bad5267be183f7352","permalink":"https://aemami.ca/publication/taleb-2015-efficacy/","publishdate":"2024-06-28T23:12:02.147468Z","relpermalink":"/publication/taleb-2015-efficacy/","section":"publication","summary":"The artificial pancreas (AP) in its 2 versions, single-hormone AP (insulin only; SAP) and dual-hormone AP (insulin and glucagon; DAP), is a promising modality for the treatment of type 1 diabetes (T1D). We conducted an open-label, randomized, crossover study comparing SAP and DAP in 17 adults (age of 37.2±13.6 years, HBA1c 8.0±1.0%, during 2 types of exercises reported to have different hypoglycemic risks: moderate-intensity continuous exercise (60% VO2peak for 60 min) and high-intensity interval exercise (2 min alternating intervals at 85% and 50% VO2peak for 40 min, with 2×10 min at 45% VO2peak at the start and the end of the sessions). SAP and DAP were applied from 15:30 till 19:30, exercise started at 18:00 and announced 20 minutes earlier to the AP systems. During SAP as compared to DAP: exercise-induced hypoglycemia (plasma glucose ≤3.3 mmol/L with symptoms or \u003c3 regardless of symptoms) was observed in 31.25% (10/32) vs. 9% (3/33) of interventions (p=0.02); the median (IQR) percentage of time with glucose \u003c4.0 mmol/L was 11 (0 to 46.7)% vs. 0 (0 to 0)% (p=0.0001); time with glucose between 4 and 10 mmol/L was 71.4 (53.2 to 100)% vs. 100 (100 to 100)% (p=0.003); the median area under the curve for glucose \u003c4.0 mmol/L was 31.6 (0 to 153.9 vs. 0 (0 to 0) mmol/L×min per h (p=0.0001). Higher doses of glucagon were needed during the continuous exercise 14.4 (9.5 to 16.9) mg vs. the interval exercise sessions 8.5 (4.6 to 16.9) mg (p=0.03). In summary, DAP is offering a tighter control and a better potential to prevent hypoglycemia during exercise in adults with T1D.","tags":null,"title":"The efficacy of single-and dual-hormone artificial pancreas systems at regulating glucose levels during continuous and interval exercise in type 1 diabetes","type":"publication"},{"authors":["Sheldon Magder","Ali Emami"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719718320,"objectID":"3be0f34f0a65789f64b7fec5f3c39f0d","permalink":"https://aemami.ca/publication/magder-2014-practical/","publishdate":"2024-06-28T23:12:02.132902Z","relpermalink":"/publication/magder-2014-practical/","section":"publication","summary":"The late Peter Stewart developed an approach to the analysis of acid-base disturbances in biological systems based on basic physical-chemical principles. His key argument was that the traditional carbon dioxide/bicarbonate analysis with just the use of the Henderson-Hasselbalch equation does not account for the important role in the regulation of H(+) concentration played by strong ions, weak acids and water itself. Acceptance of his analysis has been limited because it requires a complicated set of calculations to account for all the variables and it does not provide simple clinical guidance. However, the analysis can be made more pragmatic by using a series of simple equations to quantify the major processes in acid-base disturbances. These include the traditional PCO2 component and the addition of four metabolic processes, which we classify as \"water-effects,\" \"chloride-effects,\" \"albumin effects,\" and \"others.\" Six values are required for the analysis: [Na(+)], [Cl(-)], pH, Pco2, albumin concentration, and base excess. The advantage of this approach is that it gives a better understanding of the mechanisms behind acid-base abnormalities and more readily leads to clinical actions that can prevent or correct the abnormalities. We have developed a simple free mobile app that can be used to input the necessary values to use this approach at the bedside (Physical/Chemical Acid Base Calculator)","tags":null,"title":"Practical Approach to Physical-Chemical Acid-Base Management: Stewart at the Bedside","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719653759,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://aemami.ca/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"Awards and Nominations 2024: Faculty of Math and Sciences Teaching Award, Brock University, $2,500. [Details]\n2021: Oral Presentation at ACL 2021. [Video]\n2020: Oral Presentation at Coling 2020\n2019: Oral Presentation at EMNLP 2019\n2018: Best Paper Award\u0026ndash;NAACL SRW 2018. [Details]\n2017: The Fonds de recherche du Québec Nature et technologies (FRQNT) - PhD Scholarship, $63,000 [Declined]\n2015: McGill University Graduate Excellence Award, $4,000\n2013: William Dawson Undergraduate Excellence Award, $2,000\nFunding 2023: New Frontiers in Research Fund (NFRF) Exploration Grant, $200,000. [Details]\n2022:\nNatural Sciences and Engineering Research Council of Canada\u0026rsquo;s (NSERC) Discovery Launch Supplement, $12,500. [Details] NSERC\u0026rsquo;s Discovery Grant, $125,000. [Details] 2017: NSERC Canada Graduate Scholarship - PhD Program, $63,000\n2015 - 2017:\nNSERC Canada Graduate Scholarships-Master\u0026rsquo;s Program, $17,500 (each year) Fonds de Recherche Santé Quebec (FRSQ) Master\u0026rsquo;s Scholarship, $15,000 (each year) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719882757,"objectID":"265d605c4b78384780091475ccb6b608","permalink":"https://aemami.ca/award/awardlist/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/award/awardlist/","section":"award","summary":"Awards and Nominations 2024: Faculty of Math and Sciences Teaching Award, Brock University, $2,500. [Details]\n2021: Oral Presentation at ACL 2021. [Video]\n2020: Oral Presentation at Coling 2020\n2019: Oral Presentation at EMNLP 2019","tags":null,"title":"","type":"award"},{"authors":null,"categories":null,"content":"2025:\nEssentials of Artificial Intelligence (COSC 1P73). Overview of AI principles, ML models, and their real-world applications. New course introduced by me. (Winter) Natural Language Processing (COSC 5P84). Focuses on deep learning models for NLP and their application. New course introduced by me. (Winter) 2024:\nIntroduction to Natural Language Processing (COSC 4P84). An advanced course covering algorithms and recent advances in NLP. New course introduced by me. (Winter) Data Structures and Abstraction (COSC 1P03). Programming and problem-solving using high-level languages, data structures such as arrays, and linked lists, and abstraction. (Fall, Winter) 2023:\nNatural Language Processing (COSC 5P84). Focuses on deep learning models for NLP and their application. New course introduced by me. (Winter) Data Structures and Abstraction (COSC 1P03). Programming and problem-solving using high-level languages, data structures such as arrays, and linked lists, and abstraction. (Fall, Winter) Internet Technologies (COSC 2P89). The essential technologies and protocols for web and internet development. (Fall) 2022:\nData Structures and Abstraction (COSC 1P03). Programming and problem-solving using high-level languages, data structures such as arrays, and linked lists, and abstraction. (Winter) Programming Languages (COSC 2P05). Examination of various programming paradigms and their implications. (Winter) Internet Technologies (COSC 2P89). The essential technologies and protocols for web and internet development. (Fall) 2021:\nInternet Technologies (COSC 2P89). The essential technologies and protocols for web and internet development. (Fall) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720232929,"objectID":"8aad3f6aa09d2886a000dd5060b7370a","permalink":"https://aemami.ca/course/courselist/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/course/courselist/","section":"course","summary":"2025:\nEssentials of Artificial Intelligence (COSC 1P73). Overview of AI principles, ML models, and their real-world applications. New course introduced by me. (Winter) Natural Language Processing (COSC 5P84). Focuses on deep learning models for NLP and their application.","tags":null,"title":"","type":"course"},{"authors":null,"categories":null,"content":"Lab Members Director Ali Emami, Assistant Professor of Computer Science\nMSc Students Robert Morabito (2022-2023, Undergraduate; 2024-Present, MSc) Kaige Chen (Fall 2024 – Present) Kazi Nishat Anwar (Fall 2024 – Present) Nikta Gohari Sadr (Fall 2023 – Present) Sarfaroz Yunusov (Fall 2023 – Present) Abhishek Kumar (Fall 2022 – Summer 2024) Undergraduate Researchers Tyler Mcdonald (Summer 2023 – Present, NSERC Undergraduate Student Research Awardee) Sangmitra Madhusudan (Summer 2024 - Present, Brock Co-op Program) Skye Reid (Summer 2024) QiQi Gao (Summer 2022 – Summer 2023) Summer Researchers (Mitacs Globalink Interns) Ghofrane Faidi (Summer 2024) Angel Loredo (Summer 2024) Harsh Lalai (Summer 2024) June, 2024, Niagara Falls, Canada Our Mission The Brock NLP lab is dedicated to developing generalizable, transparent, and fair natural language processing tools capable of understanding, reasoning, and producing human-like text. Our research spans multiple facets of AI, with a particular focus on three key areas:\nBias Detection and Mitigation in Large Language Models (LLMs) Reasoning and Benchmarking of LLMs Machine Interpretability and Confidence Analysis Research Areas 1. Bias Detection and Mitigation in Large Language Models (LLMs) We develop innovative methods to identify and address subtle biases in LLMs, aiming to create more equitable AI systems. Our work introduces novel metrics and evaluation frameworks to measure representative and affinity biases that often go unnoticed.\nProportion of GPT-4\u0026rsquo;s preferred responses for the short poem task in CoGS, categorized by identity-specific prompts, with highlighted sectors indicating a preference for outputs from those identities. Read more about this study. Framework checklist comparing the consistency of recent debiasing methods. Read more about this study. Key Contributions:\nIntroduced the Representative Bias Score (RBS) and Affinity Bias Score (ABS) to measure subtle biases in LLMs. Developed the Creativity-Oriented Generation Suite (CoGS) for detecting biases in open-ended tasks. Proposed a protocol for measuring the consistency of debiasing techniques in language models. Recent Publications:\nKumar, A., Yunusov, S., Emami, A. (2024). Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models. In Proceedings of ACL 2024. Morabito, R., Kabbara, J., Emami, A. (2023). Debiasing should be Good and Bad: Measuring the Consistency of Debiasing Techniques in Language Models. In Findings of ACL 2023. 2. Reasoning and Benchmarking of LLMs We create innovative challenges and datasets to rigorously test the reasoning capabilities of LLMs, with a particular focus on enhancing and expanding the Winograd Schema Challenge (WSC).\nA representative output from Stable Diffusion 2.0 on a WINOVIS instance. The Diffusion Attentive Attribution Maps (DAAM) clarify the model\u0026rsquo;s focus for different terms and the correctness of its interpretation: correctly identifying \u0026lsquo;bee\u0026rsquo; and \u0026lsquo;flower\u0026rsquo; but erroneously associating \u0026lsquo;it\u0026rsquo; with the bee instead of the flower. Read more about this study. Interface of EvoGrad at https://www.evograd.com/. Read more about this study. Overview of the WSC+ generation and evaluation processes. On the left, the flowchart depicts the WSC+ generation process, using a real example generated by GPT-4. On the right, a WSC+ instance evaluation contrasts the outcomes of standard prompting and our Tree-of-Experts prompting. Read more about this study. Key Contributions:\nDeveloped WinoVis, a novel dataset for probing text-to-image models on pronoun disambiguation in multimodal contexts. Created EvoGrad, an open-source platform for dynamic WSC datasets using a human-in-the-loop approach. Introduced WSC+, an enhanced version of the WSC using a Tree-of-Experts approach. Recent Publications:\nPark, B., Janecek, M., Li, Y., Emami, A. (2024). Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge. In Proceedings of ACL 2024. Sun, J.H., \u0026amp; Emami, A. (2024). EvoGrad: A Dynamic Take on the Winograd Schema Challenge with Human Adversaries. In Proceedings of COLING-LREC 2024. Zahraei, P.S., \u0026amp; Emami, A. (2024). WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts. In Proceedings of EACL 2024. 3. Machine Interpretability and Confidence Analysis We investigate the inner workings of LLMs, focusing on their confidence-probability alignment and decision-making processes to enhance their reliability and interpretability.\nFlow diagram illustrating the process of extracting and comparing the Internal Confidence and Verbalized Certainty in an LLM. Read more about this study. Key Contributions:\nIntroduced the concept of Confidence-Probability Alignment in LLMs. Developed novel prompting techniques to encourage model introspection and self-evaluation. Proposed a framework for assessing model stability in dynamic tasks through the error depth metric. Recent Publication:\nKumar, A., Morabito, R., Umbet, S., Kabbara, J., Emami, A. (2024). Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models. In Proceedings of ACL 2024. We are dedicated to advancing the development of more reliable, unbiased, and interpretable language models, with our work regularly presented at conferences such as ACL, COLING-LREC, and EACL.\nResearch Focus Areas A fun word cloud generated from all of our research works!\nMap of Student Origins Join Us We are recruiting new graduate students for Fall, 2024\nUndergraduates: Please don\u0026rsquo;t hesitate to email me to inquire about research projects that I (or better, yet, you) may have in mind. Please also attach your transcript as well as a brief description of which areas of my research interests (e.g., natural language processing) you would like to work on and why. I highly encourage, and prefer, students that are planning on a summer internship (under the NSERC USRA or SURA program), or are planning to do an Honour\u0026rsquo;s thesis.\nGraduates: M.Sc. (Computer Science) and PhD (Intelligent Systems and Data Science) admissions are handled centrally in our department. Please see this page for application instructions.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720236685,"objectID":"63076c572b4be7d3d09078b9d1ad8ada","permalink":"https://aemami.ca/lab/lablist/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/lab/lablist/","section":"lab","summary":"Lab Members Director Ali Emami, Assistant Professor of Computer Science\nMSc Students Robert Morabito (2022-2023, Undergraduate; 2024-Present, MSc) Kaige Chen (Fall 2024 – Present) Kazi Nishat Anwar (Fall 2024 – Present) Nikta Gohari Sadr (Fall 2023 – Present) Sarfaroz Yunusov (Fall 2023 – Present) Abhishek Kumar (Fall 2022 – Summer 2024) Undergraduate Researchers Tyler Mcdonald (Summer 2023 – Present, NSERC Undergraduate Student Research Awardee) Sangmitra Madhusudan (Summer 2024 - Present, Brock Co-op Program) Skye Reid (Summer 2024) QiQi Gao (Summer 2022 – Summer 2023) Summer Researchers (Mitacs Globalink Interns) Ghofrane Faidi (Summer 2024) Angel Loredo (Summer 2024) Harsh Lalai (Summer 2024) June, 2024, Niagara Falls, Canada Our Mission The Brock NLP lab is dedicated to developing generalizable, transparent, and fair natural language processing tools capable of understanding, reasoning, and producing human-like text.","tags":null,"title":"","type":"lab"},{"authors":null,"categories":null,"content":"2024:\nHonored to receive the 2024 Faculty of Mathematics and Science Excellence in Teaching Award (June). 3 out of 3 submitted papers accepted at the main conference at The 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024, August 11-16). Massive congratulations to all collaborators, of which many were undergraduates and first year MSc\u0026rsquo;s! Stay tuned for the paper links (May). Our paper \u0026ldquo;EvoGrad: An open-source platform for Winograd Schema Challenge instances\u0026rdquo; accepted at The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024, May 20-25). [ArXiv] (May) Our paper \u0026ldquo;WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts\u0026rdquo; accepted as an Oral Presentation at The 18th Conference of the European Chapter of the Association for Computational Linguistics (EACL2024, March 17-22). [ACL-Anthology] [ArXiv] (March) Excited to give a talk at the Brock Faculty of Math and Science\u0026rsquo;s Anthropocene Research Colloquium Series on Friday, March 8: \u0026ldquo;Large Language Models: Society\u0026rsquo;s Silent Mirrors\u0026rdquo; (March). 2023:\nOur paper \u0026ldquo;Debiasing should be Good and Bad: Measuring the Consistency of Debiasing Techniques in Language Models\u0026rdquo; published at The Findings of ACL 2023. [ACL-Anthology] [ArXiv] [Oral Presentation] [News Article] (January) Published book chapter \u0026ldquo;Natural Language Processing: Current Methods and Challenges\u0026rdquo; in Engineering Mathematics and Artificial Intelligence: Foundations, Methods, and Applications. [SpringerLink] [Amazon] Awarded the 2023 New Frontiers in Research Fund (NFRF) Exploration Grant ($200,000 two-year support). [Brock News Article] (April) Invited to speak about my research at the SKEMA AI School for Business, during their AI integration seminar (August). Invited to discuss \u0026ldquo;Navigating the Power and Pitfalls of Pretrained Language Models in the Prompting Era\u0026rdquo; at the MIT Media Lab (May). 2022:\nAwarded the 2022 NSERC Discovery Grant ($125,000, five-year support) and 2022 Discovery Launch Supplement ($12,500). [Brock News Article] (June) Published \u0026ldquo;Interpreting docstrings without using common sense: the private science of very large language models\u0026rdquo; for Free Software Foundation (FSF): Philosophical and Legal Questions around Copilot, 2022. [FSF] Keynote speaker at the International Symposium on \u0026ldquo;Role of Basic Sciences for Sustainable Development\u0026rdquo; (October). Delivered insights on AI integration in a seminar at SKEMA AI School for Business (July). Masterclass presentation at SKEMA AI School for Business on \u0026ldquo;Generalizable, Ethical, and Interpretable Natural Language Processing: Science or Science Fiction?\u0026rdquo; (June). 2021: Gave a talk titled \u0026ldquo;Towards Interpretable, Ethical, and Generalizable NLP Models\u0026rdquo; for a graduate seminar at the Department of Computer Science, Lakehead University, Thunder Bay, Canada (October).\n2020: Selected for an oral presentation at the 28th International Conference on Computational Linguistics (COLING 2020) (December).\n2019:\nGave an oral presentation of our research at the 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019) (July). Program Committee member at 2019 ACL Student Research Workshop (SRW). Keynote at the Annual Microsoft Research and Mila Collaborative Research Workshop (October). 2018: Presented our awarded outstanding paper at the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop (NAACL 2018) (June).\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719945464,"objectID":"ebfbd6ffa84596a48af488477be4dc0c","permalink":"https://aemami.ca/news/newslist/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/news/newslist/","section":"news","summary":"2024:\nHonored to receive the 2024 Faculty of Mathematics and Science Excellence in Teaching Award (June). 3 out of 3 submitted papers accepted at the main conference at The 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024, August 11-16).","tags":null,"title":"","type":"news"},{"authors":null,"categories":null,"content":"Conference Area Chair 2024: ACL Rolling Review June 2024, Area Chair (8 papers) Conference Reviewer 2024: April 2024 ARR, The 1st Conference on Language modeling (COLM 2024), 6 papers 2023: EACL 2023 (ARR), NAACL 2023 (ARR), ACL 2024 (ARR), , 13 papers 2021: ACL 2021, 3 papers 2019: ACL SRW 2019, 3 papers Conference Organization 2019: EMNLP-IJCNLP 2019 Workshop on Commonsense Inference in Natural Language Processing, Program Committee (PC) member Internal Service 2024: Hardware/Software Planning Committee Chair, Department of Computer Science, Brock University (July 2024 \u0026ndash; Present) Undergraduate Thesis Program Coordinator, Department of Computer Science, Brock University (July 2024 \u0026ndash; Present) Joint AI BSc + BA Artificial Intelligence Program Vice Chair, Department of Computer Science, Brock University (July 2023 \u0026ndash; Present) AI Advisory Committee Member, Brock University (June 2023 \u0026ndash; Present) Inclusion, Diversity, Equitability, and Accessibility (IDEA) Lead Member, Faculty of Math and Sciences, Brock University (June 2023 \u0026ndash; Present) 2023: AI-Day Organizer, Department of Computer Science, Brock University (July 2023) Curriculum Committee Member, Department of Computer Science, Brock University (July 2023 \u0026ndash; July 2024) 2022: Hardware/Software Planning Committee Member, Department of Computer Science, Brock University (July 2022 \u0026ndash; June 2024) Professional Development and Outreach 2024: Developer and Facilitator at Brock University Professional and Continuing Studies (April 2024-Present) [Details] Workshops: C-Suite: What you need to know about AI for your business – A half-day workshop designed for business leaders to understand AI\u0026rsquo;s impact and potential in the corporate world. Exploring large language models: Beyond ChatGPT – Focuses on practical applications of LLMs in various industries. AI Essentials – A six-week micro-credential course aimed at professionals new to the AI field. ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719945133,"objectID":"32edc01a5f28bb7ec1034f06578eef25","permalink":"https://aemami.ca/service/servicelist/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/service/servicelist/","section":"service","summary":"Conference Area Chair 2024: ACL Rolling Review June 2024, Area Chair (8 papers) Conference Reviewer 2024: April 2024 ARR, The 1st Conference on Language modeling (COLM 2024), 6 papers 2023: EACL 2023 (ARR), NAACL 2023 (ARR), ACL 2024 (ARR), , 13 papers 2021: ACL 2021, 3 papers 2019: ACL SRW 2019, 3 papers Conference Organization 2019: EMNLP-IJCNLP 2019 Workshop on Commonsense Inference in Natural Language Processing, Program Committee (PC) member Internal Service 2024: Hardware/Software Planning Committee Chair, Department of Computer Science, Brock University (July 2024 \u0026ndash; Present) Undergraduate Thesis Program Coordinator, Department of Computer Science, Brock University (July 2024 \u0026ndash; Present) Joint AI BSc + BA Artificial Intelligence Program Vice Chair, Department of Computer Science, Brock University (July 2023 \u0026ndash; Present) AI Advisory Committee Member, Brock University (June 2023 \u0026ndash; Present) Inclusion, Diversity, Equitability, and Accessibility (IDEA) Lead Member, Faculty of Math and Sciences, Brock University (June 2023 \u0026ndash; Present) 2023: AI-Day Organizer, Department of Computer Science, Brock University (July 2023) Curriculum Committee Member, Department of Computer Science, Brock University (July 2023 \u0026ndash; July 2024) 2022: Hardware/Software Planning Committee Member, Department of Computer Science, Brock University (July 2022 \u0026ndash; June 2024) Professional Development and Outreach 2024: Developer and Facilitator at Brock University Professional and Continuing Studies (April 2024-Present) [Details] Workshops: C-Suite: What you need to know about AI for your business – A half-day workshop designed for business leaders to understand AI\u0026rsquo;s impact and potential in the corporate world.","tags":null,"title":"","type":"service"},{"authors":null,"categories":null,"content":"Invited talks 2024:\nIn Search of Digital Truth. Feature Presentation, First Ontario Performing Arts Centre, November. [Details] Large Language Models: Society\u0026rsquo;s Silent Mirrors. Brock Faculty of Math and Science\u0026rsquo;s Anthropocene Research Colloquium Series, March. [Details] 2023:\nLanguage Models at Scale: Big Models, Bigger Questions. Expert Panelist, Brock University\u0026rsquo;s Annual AI Day Event, November. [Details] Research Talk. AI integration seminar, SKEMA AI School for Business, August. Navigating the Power and Pitfalls of Pretrained Language Models in the Prompting Era. Research Talk, MIT Media Lab, April. 2022:\nRole of Basic Sciences for Sustainable Development. Keynote Talk, COMSTECH - OIC Standing Committee on Scientific and Technological Cooperation, October. [Details] Research Talk. AI integration seminar, SKEMA AI School for Business, July. Generalizable, Ethical, and Interpretable Natural Language Processing: Science or Science Fiction? Masterclass, SKEMA AI School for Business, May. [Details] [Video] 2021: Towards Interpretable, Ethical, and Generalizable NLP Models. Graduate Seminar COMP-5111, Lakehead University, October. [Details]\n2020: Oral presentation. 28th International Conference on Computational Linguistics (COLING), December.\n2019:\nOral presentation. 57th Annual Meeting of the Association for Computational Linguistics (ACL), July. Keynote speaker. Annual Microsoft Research and Mila Collaborative Research Workshop, October. 2018: Oral presentation (awarded best paper). 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop, June. [Video]\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719937113,"objectID":"cd2b8b3861bb3fa04d5ad74e8da495df","permalink":"https://aemami.ca/talk/talklist/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talk/talklist/","section":"talk","summary":"Invited talks 2024:\nIn Search of Digital Truth. Feature Presentation, First Ontario Performing Arts Centre, November. [Details] Large Language Models: Society\u0026rsquo;s Silent Mirrors. Brock Faculty of Math and Science\u0026rsquo;s Anthropocene Research Colloquium Series, March.","tags":null,"title":"","type":"talk"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719683358,"objectID":"9b10c1f64082d3869fd4cb1f85809430","permalink":"https://aemami.ca/terms/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/terms/","section":"","summary":"","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":" Awards and Nominations 2024: Faculty of Math and Sciences Teaching Award, Brock University, $2,500. [Details]\n2021: Oral Presentation at ACL 2021. [Video]\n2020: Oral Presentation at Coling 2020\n2019: Oral Presentation at EMNLP 2019\n2018: Best Paper Award\u0026ndash;NAACL SRW 2018. [Details]\n2017: The Fonds de recherche du Québec Nature et technologies (FRQNT) - PhD Scholarship, $63,000 [Declined]\n2015: McGill University Graduate Excellence Award, $4,000\n2013: William Dawson Undergraduate Excellence Award, $2,000\nFunding 2023: New Frontiers in Research Fund (NFRF) Exploration Grant, $200,000. [Details]\n2022:\nNatural Sciences and Engineering Research Council of Canada\u0026rsquo;s (NSERC) Discovery Launch Supplement, $12,500. [Details]\nNSERC\u0026rsquo;s Discovery Grant, $125,000. [Details]\n2017: NSERC Canada Graduate Scholarship - PhD Program, $63,000\n2015 - 2017:\nNSERC Canada Graduate Scholarships-Master\u0026rsquo;s Program, $17,500 (each year)\nFonds de Recherche Santé Quebec (FRSQ) Master\u0026rsquo;s Scholarship, $15,000 (each year)\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719683358,"objectID":"8937d27e34a95aa77f6e4e496f46e018","permalink":"https://aemami.ca/award/awards/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/award/awards/","section":"award","summary":"Awards and Nominations 2024: Faculty of Math and Sciences Teaching Award, Brock University, $2,500. [Details]\n2021: Oral Presentation at ACL 2021. [Video]\n2020: Oral Presentation at Coling 2020\n2019: Oral Presentation at EMNLP 2019","tags":null,"title":"Awards","type":"award"},{"authors":null,"categories":null,"content":" Lab Members Director Ali Emami, Assistant Professor of Computer Science\nMSc Students Robert Morabito (2022-2023, Undergraduate; 2024-Present, MSc)\nKaige Chen (Fall 2024 – Present)\nKazi Nishat Anwar (Fall 2024 – Present)\nNikta Gohari Sadr (Fall 2023 – Present)\nSarfaroz Yunusov (Fall 2023 – Present)\nAbhishek Kumar (Fall 2022 – Summer 2024)\nUndergraduate Researchers Tyler Mcdonald (Summer 2023 – Present, NSERC Undergraduate Student Research Awardee)\nSangmitra Madhusudan (Summer 2024 - Present, Brock Co-op Program)\nSkye Reid (Summer 2024)\nQiQi Gao (Summer 2022 – Summer 2023)\nSummer Researchers (Mitacs Globalink Interns) Ghofrane Faidi (Summer 2024)\nAngel Loredo (Summer 2024)\nHarsh Lalai (Summer 2024)\nJune, 2024, Niagara Falls, Canada Our Mission The Brock NLP lab is dedicated to developing generalizable, transparent, and fair natural language processing tools capable of understanding, reasoning, and producing human-like text. Our research spans multiple facets of AI, with a particular focus on three key areas:\nBias Detection and Mitigation in Large Language Models (LLMs)\nReasoning and Benchmarking of LLMs\nMachine Interpretability and Confidence Analysis\nResearch Areas 1. Bias Detection and Mitigation in Large Language Models (LLMs) We develop innovative methods to identify and address subtle biases in LLMs, aiming to create more equitable AI systems. Our work introduces novel metrics and evaluation frameworks to measure representative and affinity biases that often go unnoticed.\nProportion of GPT-4\u0026rsquo;s preferred responses for the short poem task in CoGS, categorized by identity-specific prompts, with highlighted sectors indicating a preference for outputs from those identities. Read more about this study. Framework checklist comparing the consistency of recent debiasing methods. Read more about this study. Key Contributions:\nIntroduced the Representative Bias Score (RBS) and Affinity Bias Score (ABS) to measure subtle biases in LLMs.\nDeveloped the Creativity-Oriented Generation Suite (CoGS) for detecting biases in open-ended tasks.\nProposed a protocol for measuring the consistency of debiasing techniques in language models.\nRecent Publications:\nKumar, A., Yunusov, S., Emami, A. (2024). Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models. In Proceedings of ACL 2024.\nMorabito, R., Kabbara, J., Emami, A. (2023). Debiasing should be Good and Bad: Measuring the Consistency of Debiasing Techniques in Language Models. In Findings of ACL 2023.\n2. Reasoning and Benchmarking of LLMs We create innovative challenges and datasets to rigorously test the reasoning capabilities of LLMs, with a particular focus on enhancing and expanding the Winograd Schema Challenge (WSC).\nA representative output from Stable Diffusion 2.0 on a WINOVIS instance. The Diffusion Attentive Attribution Maps (DAAM) clarify the model\u0026rsquo;s focus for different terms and the correctness of its interpretation: correctly identifying \u0026lsquo;bee\u0026rsquo; and \u0026lsquo;flower\u0026rsquo; but erroneously associating \u0026lsquo;it\u0026rsquo; with the bee instead of the flower. Read more about this study. Interface of EvoGrad at https://www.evograd.com/. Read more about this study. Overview of the WSC+ generation and evaluation processes. On the left, the flowchart depicts the WSC+ generation process, using a real example generated by GPT-4. On the right, a WSC+ instance evaluation contrasts the outcomes of standard prompting and our Tree-of-Experts prompting. Read more about this study. Key Contributions:\nDeveloped WinoVis, a novel dataset for probing text-to-image models on pronoun disambiguation in multimodal contexts.\nCreated EvoGrad, an open-source platform for dynamic WSC datasets using a human-in-the-loop approach.\nIntroduced WSC+, an enhanced version of the WSC using a Tree-of-Experts approach.\nRecent Publications:\nPark, B., Janecek, M., Li, Y., Emami, A. (2024). Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge. In Proceedings of ACL 2024.\nSun, J.H., \u0026amp; Emami, A. (2024). EvoGrad: A Dynamic Take on the Winograd Schema Challenge with Human Adversaries. In Proceedings of COLING-LREC 2024.\nZahraei, P.S., \u0026amp; Emami, A. (2024). WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts. In Proceedings of EACL 2024.\n3. Machine Interpretability and Confidence Analysis We investigate the inner workings of LLMs, focusing on their confidence-probability alignment and decision-making processes to enhance their reliability and interpretability.\nFlow diagram illustrating the process of extracting and comparing the Internal Confidence and Verbalized Certainty in an LLM. Read more about this study. Key Contributions:\nIntroduced the concept of Confidence-Probability Alignment in LLMs.\nDeveloped novel prompting techniques to encourage model introspection and self-evaluation.\nProposed a framework for assessing model stability in dynamic tasks through the error depth metric.\nRecent Publication:\nKumar, A., Morabito, R., Umbet, S., Kabbara, J., Emami, A. (2024). Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models. In Proceedings of ACL 2024. We are dedicated to advancing the development of more reliable, unbiased, and interpretable language models, with our work regularly presented at conferences such as ACL, COLING-LREC, and EACL.\nResearch Focus Areas A fun word cloud generated from all of our research works!\nMap of Student Origins Join Us We are recruiting new graduate students for Fall, 2024\nUndergraduates: Please don\u0026rsquo;t hesitate to email me to inquire about research projects that I (or better, yet, you) may have in mind. Please also attach your transcript as well as a brief description of which areas of my research interests (e.g., natural language processing) you would like to work on and why. I highly encourage, and prefer, students that are planning on a summer internship (under the NSERC USRA or SURA program), or are planning to do an Honour\u0026rsquo;s thesis.\nGraduates: M.Sc. (Computer Science) and PhD (Intelligent Systems and Data Science) admissions are handled centrally in our department. Please see this page for application instructions.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720028750,"objectID":"d38ea72b4bb262bebc4f1d52fc85a13a","permalink":"https://aemami.ca/lab/lab/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/lab/lab/","section":"lab","summary":"Lab Members Director Ali Emami, Assistant Professor of Computer Science\nMSc Students Robert Morabito (2022-2023, Undergraduate; 2024-Present, MSc)\nKaige Chen (Fall 2024 – Present)\nKazi Nishat Anwar (Fall 2024 – Present)","tags":null,"title":"Lab","type":"lab"},{"authors":null,"categories":null,"content":" 2025:\nEssentials of Artificial Intelligence (COSC 1P73). Overview of AI principles, ML models, and their real-world applications. New course introduced by me. (Winter)\nNatural Language Processing (COSC 5P84). Focuses on deep learning models for NLP and their application. New course introduced by me. (Winter)\n2024:\nIntroduction to Natural Language Processing (COSC 4P84). An advanced course covering algorithms and recent advances in NLP. New course introduced by me. (Winter)\nData Structures and Abstraction (COSC 1P03). Programming and problem-solving using high-level languages, data structures such as arrays, and linked lists, and abstraction. (Fall, Winter)\n2023:\nNatural Language Processing (COSC 5P84). Focuses on deep learning models for NLP and their application. New course introduced by me. (Winter)\nData Structures and Abstraction (COSC 1P03). Programming and problem-solving using high-level languages, data structures such as arrays, and linked lists, and abstraction. (Fall, Winter)\nInternet Technologies (COSC 2P89). The essential technologies and protocols for web and internet development. (Fall)\n2022:\nData Structures and Abstraction (COSC 1P03). Programming and problem-solving using high-level languages, data structures such as arrays, and linked lists, and abstraction. (Winter)\nProgramming Languages (COSC 2P05). Examination of various programming paradigms and their implications. (Winter)\nInternet Technologies (COSC 2P89). The essential technologies and protocols for web and internet development. (Fall)\n2021:\nInternet Technologies (COSC 2P89). The essential technologies and protocols for web and internet development. (Fall) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720232929,"objectID":"b248e78ae3169a666e8d0074fe99b9e1","permalink":"https://aemami.ca/course/courses/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/course/courses/","section":"course","summary":"2025:\nEssentials of Artificial Intelligence (COSC 1P73). Overview of AI principles, ML models, and their real-world applications. New course introduced by me. (Winter)\nNatural Language Processing (COSC 5P84). Focuses on deep learning models for NLP and their application.","tags":null,"title":"Recent Courses","type":"course"},{"authors":null,"categories":null,"content":" Conference Area Chair 2024: ACL Rolling Review June 2024, Area Chair (8 papers) Conference Reviewer 2024: April 2024 ARR, The 1st Conference on Language modeling (COLM 2024), 6 papers\n2023: EACL 2023 (ARR), NAACL 2023 (ARR), ACL 2024 (ARR), , 13 papers\n2021: ACL 2021, 3 papers\n2019: ACL SRW 2019, 3 papers\nConference Organization 2019: EMNLP-IJCNLP 2019 Workshop on Commonsense Inference in Natural Language Processing, Program Committee (PC) member Internal Service 2024:\nHardware/Software Planning Committee Chair, Department of Computer Science, Brock University (July 2024 \u0026ndash; Present)\nUndergraduate Thesis Program Coordinator, Department of Computer Science, Brock University (July 2024 \u0026ndash; Present)\nJoint AI BSc + BA Artificial Intelligence Program Vice Chair, Department of Computer Science, Brock University (July 2023 \u0026ndash; Present)\nAI Advisory Committee Member, Brock University (June 2023 \u0026ndash; Present)\nInclusion, Diversity, Equitability, and Accessibility (IDEA) Lead Member, Faculty of Math and Sciences, Brock University (June 2023 \u0026ndash; Present)\n2023:\nAI-Day Organizer, Department of Computer Science, Brock University (July 2023)\nCurriculum Committee Member, Department of Computer Science, Brock University (July 2023 \u0026ndash; July 2024)\n2022:\nHardware/Software Planning Committee Member, Department of Computer Science, Brock University (July 2022 \u0026ndash; June 2024) Professional Development and Outreach 2024:\nDeveloper and Facilitator at Brock University Professional and Continuing Studies (April 2024-Present) [Details]\nWorkshops:\nC-Suite: What you need to know about AI for your business – A half-day workshop designed for business leaders to understand AI\u0026rsquo;s impact and potential in the corporate world.\nExploring large language models: Beyond ChatGPT – Focuses on practical applications of LLMs in various industries.\nAI Essentials – A six-week micro-credential course aimed at professionals new to the AI field.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719683358,"objectID":"12a7c2cfd2c800d6ed5ee7999c690802","permalink":"https://aemami.ca/service/services/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/service/services/","section":"service","summary":"Conference Area Chair 2024: ACL Rolling Review June 2024, Area Chair (8 papers) Conference Reviewer 2024: April 2024 ARR, The 1st Conference on Language modeling (COLM 2024), 6 papers","tags":null,"title":"Services","type":"service"},{"authors":null,"categories":null,"content":" Invited talks 2024:\nIn Search of Digital Truth. Feature Presentation, First Ontario Performing Arts Centre, November. [Details]\nLarge Language Models: Society\u0026rsquo;s Silent Mirrors. Brock Faculty of Math and Science\u0026rsquo;s Anthropocene Research Colloquium Series, March. [Details]\n2023:\nLanguage Models at Scale: Big Models, Bigger Questions. Expert Panelist, Brock University\u0026rsquo;s Annual AI Day Event, November. [Details]\nResearch Talk. AI integration seminar, SKEMA AI School for Business, August.\nNavigating the Power and Pitfalls of Pretrained Language Models in the Prompting Era. Research Talk, MIT Media Lab, April.\n2022:\nRole of Basic Sciences for Sustainable Development. Keynote Talk, COMSTECH - OIC Standing Committee on Scientific and Technological Cooperation, October. [Details]\nResearch Talk. AI integration seminar, SKEMA AI School for Business, July.\nGeneralizable, Ethical, and Interpretable Natural Language Processing: Science or Science Fiction? Masterclass, SKEMA AI School for Business, May. [Details] [Video]\n2021: Towards Interpretable, Ethical, and Generalizable NLP Models. Graduate Seminar COMP-5111, Lakehead University, October. [Details]\n2020: Oral presentation. 28th International Conference on Computational Linguistics (COLING), December.\n2019:\nOral presentation. 57th Annual Meeting of the Association for Computational Linguistics (ACL), July.\nKeynote speaker. Annual Microsoft Research and Mila Collaborative Research Workshop, October.\n2018: Oral presentation (awarded best paper). 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop, June. [Video]\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719683358,"objectID":"523e67a9409657937fe78a2f6d2cbdfc","permalink":"https://aemami.ca/talk/talks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talk/talks/","section":"talk","summary":"Invited talks 2024:\nIn Search of Digital Truth. Feature Presentation, First Ontario Performing Arts Centre, November. [Details]\nLarge Language Models: Society\u0026rsquo;s Silent Mirrors. Brock Faculty of Math and Science\u0026rsquo;s Anthropocene Research Colloquium Series, March.","tags":null,"title":"Talks","type":"talk"}]