---
title: 'Interpreting docstrings without using common sense: the private science of very large language models'
authors:
- Darren Abramson
- Ali Emami
date: '2022-02-02'
publication_types:
- '4'
abstract: 'Codex is a machine learning model of natural and programming languages to which OpenAI provides limited third-party access. 1 Github Copilot is a commercial product that is built on Codex. 2 In this paper, we describe some scientific concerns with Codex/Copilot that dovetail with its widely discussed ethical and legal problems. Our focus is on the scientific problems that attend Codex, with consequent weaknesses for the Copilot commercial service. In our view, ethical and scientific weaknesses are closely tied, and we describe this with a few instances.
<br>
The argument of the paper is as follows: GPT-3, the natural language model on which Codex is built, and that services such as Copilot ultimately depend on, suffers from scientific deficiencies. First we present critical remarks on Copilotâ€™s structure and underlying language model. We then present paths forward for these, identifying specific architectural features that prevent GPT-3 from competing with recent advances due to freely distributed and licensed research software.'
publication: '*Free Software Foundations **(FSF)***'
links:
- name: Paper
  url: https://www.fsf.org/licensing/copilot/interpreting-docstrings-without-using-common-sense
---
