@inproceedings{emami-etal-2021-adept,
    title = "{ADEPT}: An Adjective-Dependent Plausibility Task",
    author = "Emami, Ali  and
      Porada, Ian  and
      Olteanu, Alexandra  and
      Suleman, Kaheer  and
      Trischler, Adam  and
      Cheung, Jackie Chi Kit",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.553",
    doi = "10.18653/v1/2021.acl-long.553",
    pages = "7117--7128",
    abstract = "A false contract is more likely to be rejected than a contract is, yet a false key is less likely than a key to open doors. While correctly interpreting and assessing the effects of such adjective-noun pairs (e.g., false key) on the plausibility of given events (e.g., opening doors) underpins many natural language understanding tasks, doing so often requires a significant degree of world knowledge and common-sense reasoning. We introduce ADEPT {--} a large-scale semantic plausibility task consisting of over 16 thousand sentences that are paired with slightly modified versions obtained by adding an adjective to a noun. Overall, we find that while the task appears easier for human judges (85{\%} accuracy), it proves more difficult for transformer-based models like RoBERTa (71{\%} accuracy). Our experiments also show that neither the adjective itself nor its taxonomic class suffice in determining the correct plausibility judgement, emphasizing the importance of endowing automatic natural language understanding systems with more context sensitivity and common-sense reasoning.",
}